{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Format\n",
    "# {\n",
    "#     Classifier1: {\n",
    "#         Error_rate1: [\n",
    "#             accuracy_iter1,\n",
    "#             accuracy_iter2,\n",
    "#             ...\n",
    "#         ],\n",
    "#         Error_rate2:[\n",
    "#             ...\n",
    "#         ]\n",
    "#         ...\n",
    "#     },\n",
    "#     Classifier2: {\n",
    "#     ...      \n",
    "#     },\n",
    "#     ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianModel\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal, mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class GaussianMixtureWithLabelingError:\n",
    "    def __init__(self, n_components=2, n_sub_mixtures=1, max_iters=10, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.n_sub_mixtures = n_sub_mixtures\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self, x, init_label):\n",
    "        self.mu_vectors = []\n",
    "        self.cov_matrices = []\n",
    "        self.probs = []\n",
    "        self.alphas = []\n",
    "        num_samples = init_label.shape[0]\n",
    "        for c in range(self.n_components):\n",
    "            idx = np.nonzero(init_label == c)[0]\n",
    "            xc = x[idx,:]\n",
    "            gmm = GaussianMixture(n_components=self.n_sub_mixtures, max_iter=self.max_iters)\n",
    "            gmm.fit(xc)\n",
    "            muv = gmm.means_\n",
    "            covs = gmm.covariances_\n",
    "            pk = gmm.weights_\n",
    "            prob = len(idx) / num_samples\n",
    "            pk = pk*prob\n",
    "            for m in range(self.n_sub_mixtures):\n",
    "                self.mu_vectors.append(muv[m, :])\n",
    "                self.cov_matrices.append(covs[m, :, :])\n",
    "                self.probs.append(pk[m])\n",
    "            alpha = np.ones((self.n_components)) / self.n_components\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "\n",
    "        llr_old = -1e100\n",
    "        for k in range(self.max_iters):\n",
    "            probx = np.zeros((self.n_components*self.n_sub_mixtures, num_samples))\n",
    "            for c in range(self.n_components):\n",
    "                for m in range(self.n_sub_mixtures):\n",
    "                    factor = 0\n",
    "                    for c2 in range(self.n_components):\n",
    "                        factor += (self.alphas[c][c2] * (init_label == c2))\n",
    "                    idcm = c*self.n_sub_mixtures + m\n",
    "                    probx[idcm, :] = multivariate_normal.pdf(x, self.mu_vectors[idcm],self.cov_matrices[idcm]) * self.probs[idcm]*factor\n",
    "\n",
    "            llr_new = np.log(probx.sum(0)).sum()\n",
    "            probx_sum = probx.sum(0)\n",
    "            probx /= probx_sum\n",
    "            probs_c =[]\n",
    "            for c in range(self.n_components):\n",
    "                prob_c = 0\n",
    "                for m in range(self.n_sub_mixtures):\n",
    "                    idcm = c*self.n_sub_mixtures + m\n",
    "                    self.probs[idcm] = probx[idcm, :].sum() / probx.sum()\n",
    "                    self.mu_vectors[idcm] = (x * (probx[idcm, :]).reshape(-1, 1)).sum(0) / (probx[idcm, :]).sum()\n",
    "                    diff_vec = x - self.mu_vectors[idcm]\n",
    "                    diff_vec2 = diff_vec * (probx[idcm, :]).reshape(-1, 1)\n",
    "                    self.cov_matrices[idcm] = np.dot(diff_vec.T, diff_vec2) / (probx[idcm, :]).sum()\n",
    "                    prob_c += probx[idcm, :]\n",
    "                probs_c.append(prob_c)\n",
    "            for c2 in range(self.n_components):\n",
    "                for c in range(self.n_components):\n",
    "                    self.alphas[c][c2] = (probs_c[c] * (init_label == c2)).sum() / (probs_c[c].sum())\n",
    "            if (llr_new - llr_old) / np.abs(llr_new) < self.tol:\n",
    "                break\n",
    "            else:\n",
    "                llr_old = llr_new\n",
    "        else:\n",
    "            print(\"Maximum number of iteration reaches\")\n",
    "            \n",
    "    def predict(self, x: np.array): # predict with no initial labels\n",
    "        num_samples = x.shape[0]\n",
    "        probx = np.zeros((self.n_components,  num_samples))\n",
    "        idcm = 0\n",
    "        for c in range(self.n_components): # for each cluster\n",
    "            for m in range(self.n_sub_mixtures): # for all sub class\n",
    "                prob_c_m = multivariate_normal.pdf(x, self.mu_vectors[idcm], self.cov_matrices[idcm])\n",
    "                probx[c,:] += prob_c_m*self.probs[idcm]\n",
    "                idcm += 1\n",
    "        probx_max = probx.max(0)\n",
    "        label = 0\n",
    "        for c in range(self.n_components):\n",
    "            label += c*(probx[c,:]==probx_max)\n",
    "        return label\n",
    "    \n",
    "    def compProb(self, x):\n",
    "        num_samples = x.shape[0]\n",
    "        probx = np.zeros((self.n_components, num_samples))\n",
    "        # probc = np.zeros((self.n_components, num_samples))\n",
    "        idcm = 0\n",
    "        for c in range(self.n_components):\n",
    "            for m in range(self.n_sub_mixtures):\n",
    "                probx[c, :] += multivariate_normal.pdf(x, self.mu_vectors[idcm], self.cov_matrices[idcm]) * self.probs[idcm]\n",
    "                #probx[c,:] *= self.probs[idcm]\n",
    "                idcm += 1\n",
    "        sum_prob = np.sum(probx,axis=0, keepdims=True)\n",
    "        probx /= sum_prob\n",
    "        return probx # classs x pixel\n",
    "\n",
    "class GaussianMixtureWithNoLabelingError:\n",
    "    def __init__(self,\n",
    "                n_components:int=2,\n",
    "                n_sub_mixtures:int=1,\n",
    "                max_iters:int=10,\n",
    "                tol:int=1e-3,\n",
    "                min_portion:int=0.01):\n",
    "        \"\"\"\n",
    "        n_components: the number of clusters\n",
    "        n_sub_mixtures: the number of sub mixtures within a cluster\n",
    "        max_iters: maximum number of iteration for model fitting\n",
    "        tol: error tolerance\n",
    "        min_portion: portion of sub_mixtures within cluser\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        if isinstance(n_sub_mixtures, int):\n",
    "            self.n_sub_mixtures = np.ones((n_components),'int') * n_sub_mixtures\n",
    "            self.num_mixtures = n_components * n_sub_mixtures\n",
    "\n",
    "        elif isinstance(n_sub_mixtures, list) or isinstance(n_sub_mixtures, np.ndarray):\n",
    "            self.n_sub_mixtures = n_sub_mixtures\n",
    "            self.num_mixtures = 0\n",
    "            for c in range(n_components):\n",
    "                self.num_mixtures += self.n_sub_mixtures[c]\n",
    "        else:\n",
    "            raise TypeError()\n",
    "\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.min_portion = min_portion\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, x:np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fit models\n",
    "        x: MxN 2-D arrray samples where M is the number of samples and N is the number of bands\n",
    "        labels: M 1-D array of the class labels\n",
    "        \"\"\"\n",
    "        self.mu_vectors = []\n",
    "        self.cov_matrices = []\n",
    "        self.probs = []\n",
    "        num_samples = labels.shape[0]\n",
    "        t1 = time.time()\n",
    "        for c in range(self.n_components):\n",
    "            idx = np.where(labels == c)[0]\n",
    "            xc = x[idx,:]  # sample with label c\n",
    "            gmm = GaussianMixture(n_components=self.n_sub_mixtures[c],\n",
    "                                    tol=self.tol,\n",
    "                                    max_iter=self.max_iters) # gmm on lable c\n",
    "            gmm.fit(xc)\n",
    "            muv = gmm.means_\n",
    "            covs = gmm.covariances_\n",
    "            pk = gmm.weights_\n",
    "            prob = len(idx) / num_samples\n",
    "            pk = pk*prob\n",
    "            for m in range(self.n_sub_mixtures[c]):\n",
    "                self.mu_vectors.append(muv[m, :])\n",
    "                self.cov_matrices.append(covs[m, :, :])\n",
    "                self.probs.append(pk[m])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x: np.array): # predict with no initial labels\n",
    "        \"\"\"\n",
    "        assign each row of x to a single cluster\n",
    "        x: MxN numpy array of samples\n",
    "        return assignment\n",
    "        \"\"\"\n",
    "        num_samples = x.shape[0]\n",
    "        probx = np.zeros((self.n_components,  num_samples))\n",
    "        idcm = 0\n",
    "        for c in range(self.n_components): # for each cluster\n",
    "            for m in range(self.n_sub_mixtures[c]): # for all sub class\n",
    "                prob_c_m = multivariate_normal.pdf(x,self.mu_vectors[idcm],self.cov_matrices[idcm])\n",
    "                probx[c,:] +=  prob_c_m*self.probs[idcm]\n",
    "                idcm += 1\n",
    "        probx_max = probx.max(0)\n",
    "        label = 0\n",
    "        for c in range(self.n_components):\n",
    "            label += c*(probx[c,:]==probx_max)\n",
    "        return label\n",
    "\n",
    "    def compProb(self, x):\n",
    "        num_samples = x.shape[0]\n",
    "        probx = np.zeros((self.n_components, num_samples))\n",
    "        # probc = np.zeros((self.n_components, num_samples))\n",
    "        idcm = 0\n",
    "        for c in range(self.n_components):\n",
    "            for m in range(self.n_sub_mixtures[c]):\n",
    "                probx[c, :] += multivariate_normal.pdf(x, self.mu_vectors[idcm], self.cov_matrices[idcm]) * self.probs[idcm] \n",
    "                #probx[c,:] *= self.probs[idcm]\n",
    "                idcm += 1\n",
    "        sum_prob = np.sum(probx,axis=0, keepdims=True)\n",
    "        probx /= sum_prob\n",
    "        return probx # classs x pixel\n",
    "\n",
    "    def saveModel(self, target_files):\n",
    "        if not self.fitted:\n",
    "            warnings.warn(\"Unable to save the model. The model has not been fitted. Run .fit()\")\n",
    "        else:\n",
    "            model_parameters = [self.n_components, self.n_sub_mixtures, self.num_mixtures, self.max_iters,\n",
    "                                self.tol, self.min_portion, self.fitted,\n",
    "                                self.probs, self.mu_vectors, self.cov_matrices]\n",
    "            np.save(target_files, model_parameters, allow_pickle=True)\n",
    "\n",
    "    def loadMode(self, model_file):\n",
    "        self.n_components, self.n_sub_mixtures, self.num_mixtures, self.max_iters,\\\n",
    "        self.tol, self.min_portion, self.fitted,\\\n",
    "        self.probs, self.mu_vectors, self.cov_matrices = np.load(model_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "\n",
    "def get_directories(path: str) -> list:\n",
    "    # Get a list of directory names in the specified path\n",
    "    directories = [entry.name for entry in os.scandir(path) if entry.is_dir()]\n",
    "    return directories\n",
    "\n",
    "def get_files(path: str) -> list:\n",
    "    # Get a list of file names in the specified path\n",
    "    files = os.listdir(path)\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_pixels(image: list, n: int=20, lower_thr: int=0, upper_thr: int=255) -> list:\n",
    "    # Get a list of pixel from image with size n * n (didn't check if list have n * n size)\n",
    "    height, width, _ = image.shape\n",
    "    mid_height, mid_width = int(height/2), int(width/2)\n",
    "    pixels = []\n",
    "    for i in range(max(0, mid_height - n), min(len(image), mid_height + n)):\n",
    "        for j in range(max(0, mid_width - n), min(len(image[0]), mid_width + n)):\n",
    "            pixel = np.array(image[i][j], dtype=int)\n",
    "            mean = pixel.mean()\n",
    "            if mean <= lower_thr or mean >= upper_thr:\n",
    "                continue \n",
    "            pixels.append(pixel)\n",
    "    return pixels\n",
    "    \n",
    "def get_ImgNameLabel(image_dir: str):\n",
    "    # Get Img, Name and Label from path\n",
    "    # path:\n",
    "    #   class1:\n",
    "    #       img1 ...\n",
    "    #   ...\n",
    "    \n",
    "    all_class_name = get_directories(image_dir)\n",
    "    all_img, all_name, label = [], [], []\n",
    "\n",
    "    for i in range(len(all_class_name)):\n",
    "        class_path = image_dir + \"/\" + all_class_name[i]\n",
    "        all_file = get_files(class_path)\n",
    "        for j, file in enumerate(all_file):\n",
    "            image = np.array(cv2.imread(class_path + \"/\" + file))   \n",
    "            all_img.append(image)\n",
    "            all_name.append(file)\n",
    "            label.append(i)\n",
    "    return np.array(all_img, dtype=object), np.array(all_name), np.array(label)\n",
    "\n",
    "def get_Rpixels(image: list, n: int=20, lower_thr: int=20, upper_thr: int=255) -> list:\n",
    "    # Get a list of pixel from image with size n * n\n",
    "    pixels = get_pixels(image, n, lower_thr, upper_thr)\n",
    "    i = 1\n",
    "    while (len(pixels) < n**2):\n",
    "        pixels = get_pixels(image, n + i, lower_thr, upper_thr)\n",
    "        i += 1\n",
    "    return pixels[:n**2]\n",
    "\n",
    "def get_Dataset_Pixel(x: np.ndarray, label: np.ndarray, require_n: int = 10, num_classes: int = 5) -> (np.ndarray, np.ndarray):\n",
    "    # Get a dataset in pixel format\n",
    "    new_x, lab = [], []\n",
    "        \n",
    "    for cls in range(num_classes):\n",
    "        idx = np.nonzero(label == cls)\n",
    "        class_images = x[idx]\n",
    "        for img in class_images:\n",
    "            s_img = get_Rpixels(img, require_n)\n",
    "            if len(s_img) != require_n ** 2:\n",
    "                continue\n",
    "            new_x += s_img\n",
    "            lab += [cls for _ in range(len(s_img))]\n",
    "\n",
    "    return np.array(new_x), np.array(lab)\n",
    "\n",
    "def get_Dataset_Img(x: np.ndarray, label: np.ndarray, require_n: int = 10, num_classes: int = 5) -> (np.ndarray, np.ndarray):\n",
    "    # Get a dataset in Image format\n",
    "    new_x, lab = [], []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        idx = np.nonzero(label == cls)\n",
    "        class_images = x[idx]\n",
    "        \n",
    "        for img in class_images:\n",
    "            s_img = get_Rpixels(img, require_n, 20, 255)\n",
    "            if len(s_img) != require_n ** 2:\n",
    "                continue\n",
    "            new_x.append(np.array(s_img).reshape(-1))\n",
    "            lab.append(cls)\n",
    "    \n",
    "    return np.array(new_x), np.array(lab)\n",
    "\n",
    "def train_test_splitV2(X: np.ndarray, label: np.ndarray, num_test: int):\n",
    "    # Split a data and make sure that each class in train data have a same size\n",
    "    train_X, test_X, train_label, test_label = [], [], [], []\n",
    "    n_class = len(np.unique(label))\n",
    "    \n",
    "    for cls in range(n_class):\n",
    "        cls_idx = np.nonzero(label == cls)\n",
    "        cls_X = X[cls_idx]\n",
    "        if len(cls_X) < num_test:\n",
    "            return\n",
    "        train_X += cls_X[:num_test].tolist()\n",
    "        train_label += [cls] * num_test\n",
    "        test_X += cls_X[num_test:].tolist()\n",
    "        test_label += [cls] * (len(cls_X[num_test:]))\n",
    "        \n",
    "    return np.array(train_X, dtype=object), np.array(test_X, dtype=object), np.array(train_label), np.array(test_label)\n",
    "\n",
    "def plot_result(result: dict):\n",
    "    err_range = result[\"err_range\"]\n",
    "    gmm = np.array([np.mean(result[\"GMM\"][str(err)]) for err in err_range])\n",
    "    gwl = np.array([np.mean(result[\"GWL\"][str(err)]) for err in err_range])\n",
    "    rfP = np.array([np.mean(result[\"RFP\"][str(err)]) for err in err_range])\n",
    "    rfI = np.array([np.mean(result[\"RFI\"][str(err)]) for err in err_range])\n",
    "    plt.errorbar(err_range, gmm, [1.96 * np.std(result[\"GMM\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"blue\", label=\"Nolabelingerror-soft\")\n",
    "    plt.errorbar(err_range, gwl, [1.96 * np.std(result[\"GWL\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"red\", label=\"Withlabelingerror-soft\")\n",
    "    plt.errorbar(err_range, rfP, [1.96 * np.std(result[\"RFP\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"green\", label=\"Nolabelingerror-hard\")\n",
    "    plt.errorbar(err_range, rfI, [1.96 * np.std(result[\"RFI\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"orange\", label=\"Withlabelingerror-hard\")\n",
    "    plt.xlabel(\"Label Error rate (%)\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n",
    "def ErrorLabelTestByErrRate(err_rate: int, softvote: bool = True):\n",
    "    # Run test with specific error rate \n",
    "    \n",
    "    #Prepare Data and Array for Output\n",
    "    pred_gmm, pred_gwl, pred_rfP, pred_rfI = [], [], [], []\n",
    "    err_per_stone = (np.random.rand(len(train_label)) < err_rate/100).astype(\"int\")\n",
    "    rdd_per_stone = np.random.choice(range(1, len(np.unique(all_label))), size=len(train_img))\n",
    "    train_label_err = train_label * (1 - err_per_stone) + ((train_label + rdd_per_stone) % len(np.unique(all_label))) * err_per_stone\n",
    "\n",
    "    # Get a dataset\n",
    "    X_trainP, lab_trainP = get_Dataset_Pixel(train_img, train_label_err, 25)\n",
    "    X_trainI, lab_trainI = get_Dataset_Img(train_img, train_label_err, 25)\n",
    "\n",
    "    # Create a Classifier\n",
    "    gmm = GaussianMixtureWithNoLabelingError(n_components=5, n_sub_mixtures=2, max_iters=80)\n",
    "    gwl = GaussianMixtureWithLabelingError(n_components=5, n_sub_mixtures=2, max_iters=80)\n",
    "    rfP = RandomForestClassifier(criterion=\"entropy\")\n",
    "    rfI = RandomForestClassifier(criterion=\"entropy\")\n",
    "    \n",
    "    # Fit the model\n",
    "    gmm.fit(X_trainP, lab_trainP)\n",
    "    gwl.fit(X_trainP, lab_trainP)\n",
    "    rfP.fit(X_trainP, lab_trainP)\n",
    "    rfI.fit(X_trainI, lab_trainI)\n",
    "            \n",
    "    # Predict the Test data\n",
    "    for i in range(len(test_img)):\n",
    "        pixel = np.array(get_Rpixels(test_img[i], 25))\n",
    "        image = [pixel.reshape(-1)]\n",
    "        \n",
    "        if softvote:\n",
    "            pred_gmm.append(int(np.argmax(np.log(gmm.compProb(pixel)).sum(1))))\n",
    "            pred_gwl.append(int(np.argmax(np.log(gwl.compProb(pixel)).sum(1))))\n",
    "            pred_rfP.append(int(np.argmax(np.log((rfP.predict_proba(pixel) + 1).sum(0)))))\n",
    "        else:\n",
    "            pred_gmm.append(int(stats.mode(gmm.predict(np.array(pixel))).mode))\n",
    "            pred_gwl.append(int(stats.mode(gwl.predict(np.array(pixel))).mode))\n",
    "            pred_rfP.append(int(stats.mode(rfP.predict(np.array(pixel))).mode))\n",
    "            \n",
    "        pred_rfI.append(int(np.argmax(np.log(rfI.predict_proba(image) + 1))))\n",
    "    return pred_gmm, pred_gwl, pred_rfP, pred_rfI\n",
    "\n",
    "def TESTER(n_loop: int = 5, softvote: bool = True, err_range: list = list(range(0, 50+1, 5))):\n",
    "    classifiers = [\"GMM\", \"GWL\", \"RFP\", \"RFI\"]\n",
    "    result = {classifier: {str(error_rate): [0 for _ in range(n_loop)] for error_rate in err_range} for classifier in classifiers}\n",
    "    for i in range(n_loop):\n",
    "        for err_rate in err_range:\n",
    "            pred_gmm, pred_gwl, pred_rfP, pred_rfI = ErrorLabelTestByErrRate(err_rate, softvote)\n",
    "            result[\"GMM\"][str(err_rate)][i] = accuracy_score(test_label, pred_gmm)\n",
    "            result[\"GWL\"][str(err_rate)][i] = accuracy_score(test_label, pred_gwl)\n",
    "            result[\"RFP\"][str(err_rate)][i] = accuracy_score(test_label, pred_rfP)\n",
    "            result[\"RFI\"][str(err_rate)][i] = accuracy_score(test_label, pred_rfI)\n",
    "    result[\"err_range\"] = err_range\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL RUN\n",
    "stone_folder = \"./Dataset/\"\n",
    "all_img, _, all_label = get_ImgNameLabel(stone_folder)\n",
    "n_class = len(np.unique(all_label))\n",
    "train_img, test_img, train_label, test_label = train_test_splitV2(all_img, all_label, 50)\n",
    "\n",
    "\n",
    "result = TESTER(softvote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "plot_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result_OldDS_Soft.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stone_folder = \"OldDS\"\n",
    "all_img, all_name, all_label = get_ImgNameLabel(stone_folder)\n",
    "n_class = len(np.unique(all_label))\n",
    "train_img, test_img, train_label, test_label = train_test_splitV2(all_img, all_label, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_ODS_Soft.json', 'r') as f:\n",
    "    result_soft = json.load(f)\n",
    "\n",
    "with open('result_ODS_Hard.json', 'r') as f:\n",
    "    result_hard = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_range = list(range(0, 51, 5))\n",
    "\n",
    "gmm = np.array([np.mean(result_soft[\"GMM\"][str(err)]) for err in err_range])\n",
    "gwl = np.array([np.mean(result_soft[\"GWL\"][str(err)]) for err in err_range])\n",
    "gmm1 = np.array([np.mean(result_hard[\"GMM\"][str(err)]) for err in err_range])\n",
    "gwl1 = np.array([np.mean(result_hard[\"GWL\"][str(err)]) for err in err_range])\n",
    "\n",
    "plt.errorbar(err_range, gmm, [1.96 * np.std(result_soft[\"GMM\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"blue\", label=\"Nolabelingerror-soft\")\n",
    "plt.errorbar(err_range, gwl, [1.96 * np.std(result_soft[\"GWL\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"red\", label=\"Withlabelingerror-soft\")\n",
    "plt.errorbar(err_range, gmm1, [1.96 * np.std(result_hard[\"RFP\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"green\", label=\"Nolabelingerror-hard\")\n",
    "plt.errorbar(err_range, gwl1, [1.96 * np.std(result_hard[\"RFI\"][str(err)])/np.sqrt(len(test_img)) for err in err_range], color=\"orange\", label=\"Withlabelingerror-hard\")\n",
    "\n",
    "plt.xlabel(\"Label Error rate (%)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
